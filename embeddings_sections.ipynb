{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings by document section\n",
    "\n",
    "Rather than using a single embedding for each *document*, we first split the document into sections (as illustrated in `split_markdown.ipynb`) and then find embeddings for each section. This should allow more relevant information to be found based on a query, as the embeddings are more specific to the section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to split a document into sections\n",
    "\n",
    "These functions are based on the one defined in `split_markdown.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_markdown(markdown_string):\n",
    "    \"\"\"Splits a markdown string into a dictionary of headings and content.\"\"\"\n",
    "    headings_regex = r'(?P<level>#+)\\s*(?P<heading>.+)'\n",
    "    headings = {}\n",
    "    current_heading = ''\n",
    "    current_content = []\n",
    "    for line in markdown_string.splitlines():\n",
    "        if heading_match := re.match(headings_regex, line):\n",
    "            if current_heading:\n",
    "                headings[current_heading] = current_content\n",
    "                current_content = []\n",
    "            current_heading = heading_match['heading']\n",
    "        elif line.strip():\n",
    "            current_content.append(line.strip())\n",
    "    if current_heading:\n",
    "        headings[current_heading] = current_content\n",
    "    return headings\n",
    "\n",
    "def parse_markdown_files(paths: list[str]) -> dict[str, dict[str, list[str]]]:\n",
    "    \"\"\"Parses a list of markdown files into a dictionary of headings and content.\"\"\"\n",
    "    markdown = {}\n",
    "    for path in paths:\n",
    "        with open(path) as f:\n",
    "            markdown[path] = parse_markdown(f.read())\n",
    "    return markdown"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define utility function to return all markdown files in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def get_markdown_files(dir, exclude_dirs_patterns: list = None):\n",
    "    \"\"\"Recursively get the paths to all markdown files in a directory, excluding any directories in exclude_dirs.\n",
    "    Directories in exclude_dirs are matched using glob syntax and may appear anywhere in the path.\"\"\"\n",
    "    if exclude_dirs_patterns is None:\n",
    "        exclude_dirs_patterns = []\n",
    "    paths = []\n",
    "    for path in glob.glob(f\"{dir}/**\", recursive=True):\n",
    "        if not path.endswith(\".md\"):\n",
    "            continue\n",
    "        # Skip any paths that match any of the exclude_dirs patterns anywhere in the path\n",
    "        if any(re.search(pattern, path) for pattern in exclude_dirs_patterns):\n",
    "            continue\n",
    "        paths.append(path)\n",
    "    return paths\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to prepare the data for embedding\n",
    "\n",
    "We'll be using a pandas dataframe to store and manipulate the dataset. Here I define a few utility functions to be used in the data pipeline, namely `count_tokens`, `filter_by_num_tokens`, and `filter_empty_content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import pandas as pd\n",
    "\n",
    "EMBEDDINGS_MODEL = \"text-embedding-ada-002\"\n",
    "EMBEDDINGS_ENCODING = \"cl100k_base\"  # encoding for ada-002\n",
    "EMBEDDINGS_MAX_TOKENS = 8000  # max tokens for ada-002\n",
    "\n",
    "encoding = tiktoken.get_encoding(EMBEDDINGS_ENCODING)\n",
    "\n",
    "def count_tokens(df) -> pd.DataFrame:\n",
    "    \"\"\"Count the number of tokens in a dataframe column.\"\"\"\n",
    "    df['n_tokens'] = df.combined.apply(lambda x: len(encoding.encode(x)))\n",
    "    return df\n",
    "\n",
    "def filter_by_num_tokens(df, n_tokens) -> pd.DataFrame:\n",
    "    \"\"\"Filter a dataframe by the number of tokens in a column.\"\"\"\n",
    "    return df[df.n_tokens <= n_tokens]\n",
    "\n",
    "def filter_empty_content(df) -> pd.DataFrame:\n",
    "    \"\"\"Remove rows with empty content.\"\"\"\n",
    "    return df[df.content != '']\n",
    "\n",
    "def combined(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Combine the filename, heading, and content into a single column, avoiding the SettingWithCopyWarning.\"\"\"\n",
    "    df.loc[:, 'combined'] = df.filename + \":\" + df.heading + \"\\n\" + df.content\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to load the data into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_documents_as_df(paths: list) -> pd.DataFrame:\n",
    "    \"\"\"Load a list of markdown files into a dataframe of sections.\"\"\"\n",
    "    parsed = parse_markdown_files(paths)\n",
    "    # create a dataframe: filename, heading, content\n",
    "    docs = pd.DataFrame(\n",
    "        [\n",
    "            (os.path.basename(path), heading, \"\\n\".join(content))\n",
    "            for path, headings in parsed.items()\n",
    "            for heading, content in headings.items()\n",
    "        ],\n",
    "        columns=[\"filename\", \"heading\", \"content\"],\n",
    "    )\n",
    "    docs = (\n",
    "        docs.pipe(filter_empty_content)\n",
    "        .pipe(combined)\n",
    "        .pipe(count_tokens)\n",
    "        .pipe(filter_by_num_tokens, EMBEDDINGS_MAX_TOKENS)\n",
    "    )\n",
    "    return docs\n",
    "\n",
    "def load_documents_as_df_from_dir(dir: str, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"Load a directory of markdown files into a dataframe of sections.\"\"\"\n",
    "    paths = get_markdown_files(dir, **kwargs)\n",
    "    return load_documents_as_df(paths)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the functions to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1028 markdown files in /home/tyto/Documents/dnd/DND.SRD.Wiki-0.5.1/.\n",
      "Found 931 markdown files in /home/tyto/Documents/dnd/DND.SRD.Wiki-0.5.1/ (excluding ['Templates', 'Alt', 'Changelog.md', 'README.md', 'Legal.md']).\n"
     ]
    }
   ],
   "source": [
    "# FOLDER = \"tmp/dnd-notes-main\"\n",
    "FOLDER = \"/home/tyto/Documents/dnd/DND.SRD.Wiki-0.5.1/\"\n",
    "EXCLUDE_DIRS = [\"Templates\", \"Alt\", \"Changelog.md\", \"README.md\", \"Legal.md\"]\n",
    "print(f\"Found {len(get_markdown_files(FOLDER, exclude_dirs_patterns=[]))} markdown files in {FOLDER}.\")\n",
    "print(f\"Found {len(get_markdown_files(FOLDER, exclude_dirs_patterns=EXCLUDE_DIRS))} markdown files in {FOLDER} (excluding {EXCLUDE_DIRS}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1954 sections from /home/tyto/Documents/dnd/DND.SRD.Wiki-0.5.1/ across 931 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788525/4200071734.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'combined'] = df.filename + \":\" + df.heading + \"\\n\" + df.content\n",
      "/tmp/ipykernel_1788525/4200071734.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['n_tokens'] = df.combined.apply(lambda x: len(encoding.encode(x)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>heading</th>\n",
       "      <th>content</th>\n",
       "      <th>combined</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paladin.md</td>\n",
       "      <td>Class Features</td>\n",
       "      <td>As a paladin, you gain the following class fea...</td>\n",
       "      <td>Paladin.md:Class Features\\nAs a paladin, you g...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paladin.md</td>\n",
       "      <td>Hit Points</td>\n",
       "      <td>**Hit Dice:** 1d10 per paladin level\\n**Hit Po...</td>\n",
       "      <td>Paladin.md:Hit Points\\n**Hit Dice:** 1d10 per ...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paladin.md</td>\n",
       "      <td>Proficiencies</td>\n",
       "      <td>**Armor:** All armor, shields\\n**Weapons:** Si...</td>\n",
       "      <td>Paladin.md:Proficiencies\\n**Armor:** All armor...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paladin.md</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>You start with the following equipment, in add...</td>\n",
       "      <td>Paladin.md:Equipment\\nYou start with the follo...</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Paladin.md</td>\n",
       "      <td>Divine Sense</td>\n",
       "      <td>The presence of strong evil registers on your ...</td>\n",
       "      <td>Paladin.md:Divine Sense\\nThe presence of stron...</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename         heading  \\\n",
       "1  Paladin.md  Class Features   \n",
       "2  Paladin.md      Hit Points   \n",
       "3  Paladin.md   Proficiencies   \n",
       "4  Paladin.md       Equipment   \n",
       "5  Paladin.md    Divine Sense   \n",
       "\n",
       "                                             content  \\\n",
       "1  As a paladin, you gain the following class fea...   \n",
       "2  **Hit Dice:** 1d10 per paladin level\\n**Hit Po...   \n",
       "3  **Armor:** All armor, shields\\n**Weapons:** Si...   \n",
       "4  You start with the following equipment, in add...   \n",
       "5  The presence of strong evil registers on your ...   \n",
       "\n",
       "                                            combined  n_tokens  \n",
       "1  Paladin.md:Class Features\\nAs a paladin, you g...        19  \n",
       "2  Paladin.md:Hit Points\\n**Hit Dice:** 1d10 per ...        64  \n",
       "3  Paladin.md:Proficiencies\\n**Armor:** All armor...        60  \n",
       "4  Paladin.md:Equipment\\nYou start with the follo...       821  \n",
       "5  Paladin.md:Divine Sense\\nThe presence of stron...       188  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_documents_as_df_from_dir(FOLDER, exclude_dirs_patterns=EXCLUDE_DIRS)\n",
    "print(f\"Loaded {len(df)} sections from {FOLDER} across {len(df.filename.unique())} files.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost of embeddings for this dataset: $0.15\n",
      "Dataset has 1954 sections, 931 documents, and 384297 tokens.\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of tokens in the dataset\n",
    "df.n_tokens.sum()\n",
    "\n",
    "# Get the number of documents in the dataset\n",
    "df.filename.nunique()\n",
    "\n",
    "# Get the number of sections in the dataset\n",
    "df.shape[0]\n",
    "\n",
    "# Get the average number of tokens in each document\n",
    "df.groupby(\"filename\").n_tokens.sum().mean()\n",
    "\n",
    "# the cost for embeddings is $0.0004 / 1K tokens, so we can calculate the cost of the dataset\n",
    "print(f\"Cost of embeddings for this dataset: ${df.n_tokens.sum() * 0.0004 / 1000:.2f}\")\n",
    "print(f\"Dataset has {df.shape[0]} sections, {df.filename.nunique()} documents, and {df.n_tokens.sum()} tokens.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and save embeddings for the content in each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f66aee3b5d4af8b2880726253608b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=245), Label(value='0 / 245'))), HBâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "from openai.embeddings_utils import get_embedding\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "df['embedding'] = df.parallel_apply(lambda x: get_embedding(text=x.content, engine=EMBEDDINGS_MODEL), axis=1)  # takes roughly 1.5 minutes on dataset with 400k tokens\n",
    "df.to_csv(f\"{FOLDER}/embeddings-sections.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnd-note-tool-z5HkzLi6-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
